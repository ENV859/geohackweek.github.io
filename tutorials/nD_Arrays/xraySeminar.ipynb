{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# geohackweek 2016\n",
    "\n",
    "## DAY 3, NOV 16\n",
    "\n",
    "### multidimensional array analysis\n",
    "![arrayLogo](https://github.com/geohackweek/geohackweek.github.io/blob/master/img/ndarray_icon.png) \n",
    "\n",
    "#### Instructors: A. Arendt, J. Hamman\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Overview:\n",
    "\n",
    "Geoscientists often need to manipulate datasets structured as arrays. A common example is gridded data consisting of a set of climate variables (e.g. temperature and precipitation) that varies in space and time. Often we need to subset a large global dataset to look at data for a particular region, or select a specific time slice. Then we might want to apply statistical functions to these subsetted groups to generate summary information.\n",
    "\n",
    "The tools in this tutorial have some similarity to raster image processing tools. Both require computational engines that can manipulate large stacks of data formatted as arrays. Here we focus on tools that are optimized to handle data that have many variables spanning dimensions of time and space, rather than image processing tools that are more targeted to remote sensing datasets.\n",
    "\n",
    "### Existing Methods:\n",
    "\n",
    "A common approach for handling multidimensional grids is to read the data into an array and then write a series of nested loops with conditional statements to look for a specific range of index values associated with the temporal or spatial slice needed. Also, clever use of matrix algebra is often used to summarize data across spatial and temporal dimensions.\n",
    "\n",
    "Many multidimensional datasets are stored in self-describing formats such as netcdf. Some organizations have developed their own netcdf toolkits that accomplish tasks like subsetting and grouping.\n",
    "\n",
    "### Challenges:\n",
    "\n",
    "Many multidimensional datasets are becoming very large as model resolution and sensing capabilities improve. Traditional methods for looping through array datasets to perform subsetting are no longer viable options for handling these large datasets, because we are limited by what our computers can read into memory. In addition, it is often challenging to keep track of index values when manipulating arrays that span multiple dimensions. \n",
    "\n",
    "### Learning Objectives: \n",
    "\n",
    "To become familiar with the xarray Python library for:\n",
    "1. selection and subsetting of array datasets using labeled indexing;\n",
    "2. grouping data and applying statistical functions across multiple dimensions;\n",
    "3. visualizing 1 and 2 dimensional slices of array data;\n",
    "4. using multi-threading libraries to facilitate manipulation of larger-than-memory grids;\n",
    "5. understand best practices for reading and storing large gridded datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is xarray?\n",
    "\n",
    "* originally developed by employees (Stephan Hoyer, Alex Kleeman and Eugene Brevdo) at [The Climate Corporation](https://climate.com/)\n",
    "* xray extends some of the core functionality of Pandas:\n",
    "    * operations over _named_ dimensions\n",
    "    * selection by label instead of integer location\n",
    "    * powerful groupby functionality\n",
    "    * database-like joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### When to use xray:\n",
    "\n",
    "* if your data are multidimensional (e.g. climate data: x, y, z, time)\n",
    "* if your data are structured on a regular grid\n",
    "* if you can represent your data in NetCDF format\n",
    "\n",
    "[xray documentation](http://xray.readthedocs.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why not just numpy?\n",
    "* joining arrays is awkward in numpy\n",
    "* labeling is limited to index position\n",
    "* arrays must be small enough to fit into memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dask:\n",
    "* many multidimensional datasets are larger-than-memory\n",
    "* xray recently integrated [Dask](http://xray.readthedocs.org/en/stable/dask.html)\n",
    "* Dask: parallel computing through task scheduling and blocked algorithms\n",
    "* from _fits in memory_ to _fits on disk_\n",
    "![chunkGraphic](http://xray.readthedocs.org/en/stable/_images/dask_array.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dask:\n",
    "* dask.array = numpy + threading\n",
    "* dask.bag = map, filter, toolz + multiprocessing\n",
    "* dask.dataframe = pandas + threading\n",
    "\n",
    "![daskGraphic](http://dask.pydata.org/en/latest/_images/collections-schedulers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![animation](http://mrocklin.github.com/blog/images/dask/embarrassing.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### General package implementation:\n",
    "\n",
    "* Anaconda distribution\n",
    "* conda install xray, dask, netCDF4 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Implementation for this seminar:\n",
    "\n",
    "* Microsoft Azure Virtual Machine: Linux Ubuntu 14.04 on DS4 VM with 8 cores and 14 GB RAM\n",
    "* [here's how](https://azure.microsoft.com/en-us/documentation/articles/virtual-machines-python-ipython-notebook/) you deploy Jupyter to the cloud\n",
    "* cloud deployment:\n",
    "    * benefit: can easily add resources to handle large datasets\n",
    "    * cost: success of xray depends on read/write speeds, and some cloud storages throttle speeds based on cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Basic xray data structures:\n",
    "* Dataset: multi-dimensional equivalent of a Pandas DataFrame\n",
    "    * dict-like container of DataArray objects\n",
    "![climate](http://xray.readthedocs.org/en/stable/_images/dataset-diagram.png)\n",
    "* dimensions (x, y, time); variables (temp, precip); coords (lat, long); attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sample datasets:\n",
    "\n",
    "* we will use climate reanalysis data from the European Center for Medium Range Weather Forecasts [ECMWF](http://www.ecmwf.int/)\n",
    "* as is the case for many climate products, the process involves downloading large netcdf files to a local machine\n",
    "* this example follows and expands from Developer Stephan Hoyer's [blog post](https://www.continuum.io/content/xray-dask-out-core-labeled-arrays-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ECMWF data query interface:\n",
    "<img src=\"https://github.com/ice2ocean/ice2ocean.github.io/blob/master/ecmwf.JPG?raw=true\" width=\"400\" height=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### File formats\n",
    "* xray exclusively works with Network Common Data Form or [NetCDF](http://www.unidata.ucar.edu/software/netcdf/) files\n",
    "* NetCDF files:\n",
    "    * are self-describing (file layout is described in the header)\n",
    "    * store data arrays as well as associated metadata\n",
    "    * allow use of Hierarchical Data Format (HDF) files (after version 4.0)\n",
    "    * note: different NetCDF versions can impact [reading of data](http://xray.readthedocs.org/en/stable/io.html#netcdf) in xray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Begin by importing the relevant libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anthony Arendt\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray\n",
    "import xarray.ufuncs as xu \n",
    "import dask\n",
    "import seaborn as sn\n",
    "from datetime import datetime\n",
    "from dask.diagnostics import ProgressBar\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Open the netcdf climate files\n",
    "* this opens a single netcdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "879605964811-dlt-utilization\n",
      "araldif\n",
      "cf-templates-1ab7um9nrai0n-us-west-2\n",
      "czardata\n",
      "czarlog\n",
      "geohack2016\n",
      "ice2ocean\n"
     ]
    }
   ],
   "source": [
    "import xarray\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "s3.Bucket(name='geohack2016').download_file('ecmwf_airtemp.nc','ecmwf_airtemp.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = xarray.open_dataset(r'c:/work/mnt/ecmwf/ecmwf_airtemp.nc', engine = 'scipy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inspect the Dataset contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dimensions\n",
    "* dimension names for each axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ds.dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Coordinates\n",
    "* a dictionary-like container of arrays labeling each point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ds.coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inspecting coordinates\n",
    "* indexing by coordinate dimension returns a data array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ds.coords['time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Attributes\n",
    "* DataSets store metadata in an ordered dictionary called _attributes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ds.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Attributes\n",
    "\n",
    "* we can assign new attributes as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ds.attrs['title'] = 'example ECMWF dataset'\n",
    "ds.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data Arrays\n",
    "* each grid cube/plane represents one data array within the collection comprising the data set\n",
    "![datasetExample](http://xray.readthedocs.org/en/stable/_images/dataset-diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data Arrays\n",
    "* each variable is a separate data array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ds.data_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data Arrays\n",
    "* when we index a specific variable, it returns a Data Array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ds['t2m']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create a plotting function for visualization\n",
    "* We use the [cartopy](http://scitools.org.uk/cartopy/) library to make maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def plotter(DataArray):\n",
    "    plt.figure(figsize=(9,5))\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "    ax.coastlines(resolution='50m')\n",
    "    ax.gridlines()\n",
    "    X = DataArray.coords['longitude'].values\n",
    "    Y = DataArray.coords['latitude'].values\n",
    "    pltData = DataArray.values\n",
    "    plt.pcolormesh(X,Y,pltData,cmap='BrBG')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plotter(ds.t2m.isel(time=100)-273.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Note our use of arithmetic operations to convert from Kelvin to degrees Celcius\n",
    "* This is automatically vectorized across the DataArray, as in numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data Array: attributes\n",
    "* in a similar fashion to a Dataset, you can inspect the Data Array coords, dims and attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ds['t2m'].attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ds.t2m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Indexing: positional, by integer\n",
    "* xray supports indexing by position and by labeled dimensions \n",
    "* positional indexing: similar to numpy arrays\n",
    "* note: attributes persist through the indexing operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ds.t2m[:,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plot: temperature at one grid cell\n",
    "* data are extracted to a variable as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds.t2m[:,0,0].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Indexing: positional, by label\n",
    "* use variable label for the index location (Pandas-like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ds.t2m.loc['1980-02-04':'1981-03-21',0,0].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Indexing: Labeled dimensions\n",
    "* no need to rely on dimension order\n",
    "* method 1:\n",
    "    * use a dictionary as the argument for positional array indexing (numpy-like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ds.t2m[dict(time=slice(0,100),latitude=slice(50,55),longitude=slice(10,12))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Indexing: Labeled dimensions\n",
    "* method 2:\n",
    "    * use a dictionary as the argument for label-based array indexing (Pandas-like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ds.t2m.loc[dict(time=slice(\"1992-01-02\",\"1993-09-25\"),\n",
    "                latitude=slice(52.5,49.5),longitude=slice(7.5,8.25))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Indexing: Labeled dimensions\n",
    "* this syntax is beginning to get cumbersome\n",
    "* xray has the following convenience methods to tidy up the syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#ds.t2m[dict(time=slice(0,100),latitude=slice(50,55),longitude=slice(10,12))]\n",
    "ds.t2m.isel(time=slice(0,100),latitude=slice(50,55),longitude=slice(10,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#ds.t2m.loc[dict(time=slice(\"1992-01-02\",\"1993-09-25\"),\n",
    "#                latitude=slice(52.5,49.5),longitude=slice(7.5,8.25))]\n",
    "\n",
    "ds.t2m.sel(time=slice(\"1992-01-02\",\"1993-09-25\"),\n",
    "           latitude=slice(52.5,49.5),longitude=slice(7.5,8.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualization of indexing applications\n",
    "* a simple application: spatial subsetting (Alaska region)\n",
    "* note: we need to [squeeze](http://xray.readthedocs.org/en/stable/generated/xray.DataArray.squeeze.html) the array for plotting purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plotData = ds.sel(time=\"1984-01-01\",latitude=slice(80,40)\n",
    "                  ,longitude=slice(190,250))\n",
    "plotter(plotData.squeeze(dim='time').t2m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Indexing: pointwise\n",
    "* all indexing so far has involved selection along orthogonal groups\n",
    "* we can also provide lists to select individual points from the grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "times = pd.to_datetime(['1992-01-02T6:00:00','1992-01-02T6:00:00'])\n",
    "ds.t2m.sel_points(time=times,latitude=[52.5,60.0],longitude=[7.5,8.25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Opening multiple netcdf files, and using Dask\n",
    "* we will use the [mfdataset](http://xray.readthedocs.org/en/stable/generated/xray.open_mfdataset.html#xray.open_mfdataset) option that opens multiple files as a single xray dataset\n",
    "* this automatically invokes the dask functionality\n",
    "* in our case, there are multiple files for each parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ds = xray.open_mfdataset(r'c:/work/mnt/ecmwf/*.nc', engine='scipy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dataset indexing\n",
    "* indexing on datasets indexes all variables simulataneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ds.sel(time=slice(\"1992-01-02\",\"1993-09-25\"),\n",
    "       latitude=slice(52.5,49.5),longitude=slice(7.5,8.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Chunk sizes:\n",
    "* in my testing, getting the chunk size right is the crucial step to optimize Dask\n",
    "* without specifying chunk size, open_mfdataset chunks along existing dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ds.chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Chunk size:\n",
    "* recommended: follow the advice [here](http://xray.readthedocs.org/en/stable/dask.html?highlight=rechunk#chunking-and-performance) regarding chunk sizes: about 1 million elements\n",
    "* in our case: 480* 241 = 115680\n",
    "* so make the time chunk 10 to get around 1 million\n",
    "* note: we're only chunking the time dimension. Choice depends on typical slicing scenarios. More testing needed!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ds = xray.open_mfdataset(r'c:/work/mnt/ecmwf/*.nc', engine='scipy', chunks = {'time':10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GroupBy processing\n",
    "* xray has powerful [GroupBy](http://xray.readthedocs.org/en/stable/groupby.html) processing tools\n",
    "* this is similar to GROUP BY processing in SQL\n",
    "* in all cases we **split** the data, **apply** a function to independent groups, and **combine** back into a known data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GroupBy processing: example\n",
    "* we often want to build a time series of change from spatially distributed data\n",
    "* let's calculate the average air temperature over the globe for the full time period\n",
    "* remember: split, apply, combine!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Groupby processing: split\n",
    "\n",
    "* we can groupby the name of a variable or coordinate\n",
    "* this returns an xray groupby object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ds.t2m.groupby('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "View the group indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ds.t2m.groupby('time').groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* output looks like this:\n",
    "\n",
    "{numpy.datetime64('1979-01-02T06:00:00.000000000+0000'): 1,\n",
    "\n",
    " numpy.datetime64('1989-03-15T06:00:00.000000000+0000'): 3726,\n",
    "\n",
    " numpy.datetime64('2006-03-29T06:00:00.000000000+0000'): 9949,\n",
    " \n",
    " numpy.datetime64('2004-04-16T06:00:00.000000000+0000'): 9237,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Groupby processing: apply\n",
    "* when providing a single dimension to the GroupBy command, xray applies the function across the remaining dimensions\n",
    "* we could do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def mean(x):\n",
    "    return x.mean()\n",
    "\n",
    "ds.t2m.groupby('time').apply(mean).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* however, groupby objects have convenient shortcuts (see next slide)\n",
    "* but, use this approach if the function is non-standard "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Groupby processing: apply\n",
    "* now an acutal calculation: \n",
    "    * we'll use dask's [diagnostic tools](http://dask.pydata.org/en/latest/diagnostics.html) to monitor the processing\n",
    "    * we'll use xray's new [plotting](http://xray.readthedocs.org/en/stable/plotting.html) capabilities\n",
    "    * when a single dimension is provided, xray applies the function over all dimensions _other than_ that dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    ds.t2m.groupby('time').mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* we can group over any number of [time components](http://xray.readthedocs.org/en/stable/time-series.html#datetime-components)\n",
    "* here's the global average annual air temperature since 1979 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    ds.t2m.groupby('time.year').mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conversion to Pandas\n",
    "* we can use \".to_series()\" to convert an xray data array to a Pandas data series\n",
    "* then, use Pandas methods on the series to resample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    ds.t2m.groupby('time').mean().to_series().resample('A',how='mean').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Groupby: advanced temporal grouping\n",
    "* xray introduces the 'season' time component, common in climate studies\n",
    "* and it turns out, xray's new [.plot()](http://xray.readthedocs.org/en/stable/plotting.html) functionality operates on spatial maps as well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* here is the mean differences between summer and winter global temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ds_by_season = ds.t2m.groupby('time.season').mean('time')\n",
    "t2m_range = abs(ds_by_season.sel(season='JJA')\n",
    "                 - ds_by_season.sel(season='DJF'))\n",
    "t2m_range.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Calculation of wind vectors\n",
    "\n",
    "* xray exposes numpy [ufunc](http://docs.scipy.org/doc/numpy/reference/ufuncs.html) commands that can operate on data arrays\n",
    "* here we'll calculate windspeed from the orthogonal wind vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "subset = ds.sel(time=\"1984-01-01\",latitude=slice(70,40),\n",
    "                longitude=slice(200,240)).squeeze(dim='time')\n",
    "windspeed = xu.sqrt(subset.u10**2+subset.v10**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,5))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines(resolution='50m')\n",
    "ax.gridlines()\n",
    "X = windspeed.coords['longitude'].values\n",
    "Y = windspeed.coords['latitude'].values\n",
    "plt.pcolormesh(X,Y,windspeed.values,cmap='BrBG')\n",
    "ax.quiver(X, Y, subset.u10.values, subset.v10.values)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Masking with WHERE:\n",
    "* so far we have used indexing to return subsets of the original\n",
    "* the subset array shape will be different from the original\n",
    "* however, we often want to retain the array shape and mask out some observations\n",
    "* applications: remote sensing, land cover modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Masking with WHERE:\n",
    "* question: which grid cells had temperatures > 12 C on June 21, 1984?\n",
    "* we will use [where()](http://xray.readthedocs.org/en/stable/indexing.html#masking-with-where) for this selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "subset = ds.sel(time=\"1984-06-21\",latitude=slice(70,40),\n",
    "                longitude=slice(200,240))\n",
    "subset.t2m.where(subset.t2m > 285.15).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Masking with WHERE:\n",
    "* a common Earth science application: creating land cover masks\n",
    "* next we'll use the sea surface temperature field (sst) to build a land and ocean mask \n",
    "* we'll assign land a value of 1, and ocean a value of 2 (arbitrary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Land/ocean mask\n",
    "* the sst field currently has NaN for all land surfaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "subset = ds.sel(latitude=slice(70,40),longitude=slice(200,240)) # Alaska subset\n",
    "subset.sst.isel(time=0).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Buliding the mask:\n",
    "* here we'll use some lower-level numpy commands to build the mask\n",
    "* mask number depends on whether the cells are finite or NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "maskOcean = 2 * np.ones((subset.dims['latitude'],\n",
    "                         subset.dims['longitude'])) \\\n",
    "                        * np.isfinite(subset.sst.isel(time=0))  \n",
    "\n",
    "maskLand = 1 * np.ones((subset.dims['latitude'],\n",
    "                        subset.dims['longitude'])) \\\n",
    "                        * np.isnan(subset.sst.isel(time=0))  \n",
    "\n",
    "maskArray = maskOcean + maskLand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mask as Coordinates\n",
    "* we can keep the mask as a separate array entity\n",
    "* or, if we are using it routinely, there are advantages to [adding it](http://xray.readthedocs.org/en/stable/data-structures.html#dataarray-coordinates) as a coordinate to the data array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "subset.coords['mask'] = (('latitude','longitude'),maskArray)\n",
    "subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Here's a visualization of the land/ocean mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "subset.mask.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mask as Coordinates\n",
    "* now we can easily apply the mask using where()\n",
    "* we can integrate this with statistical functions operating on the array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* this is the mean air temperature over Alaska during the entire period of record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "subset.t2m.mean('time').where(subset.mask == 1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " ds.temperature.groupby('time').mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* similarly, this is the mean SST over the full time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "subset.sst.mean('time').where(subset.mask == 2).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Calculating a climate index:\n",
    "* climate scientists commonly calculate mean diferences in sea and land surface temperatures\n",
    "* question: what is the mean annual difference in SST and t2m over the Alaska region? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "landSft = subset.t2m.where(subset.mask == 1).groupby('time.year').mean()\n",
    "oceanSft = subset.sst.where(subset.mask == 2).groupby('time.year').mean()\n",
    "landSft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* here's a plot of the index, showing mean annual differences in land/ocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "climateIndex = (landSft - oceanSft).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Groupby on two dimensional mask?\n",
    "* our mask is 2D (lat, long)\n",
    "* wouldn't it be useful to groupby this mask directly? \n",
    "* this would be more elegant than above, and add some additional flexibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "subset.t2m.groupby('mask').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* if we run this, there are errors\n",
    "* the xray team is working on removing the 1-D limitation on groupby operations\n",
    "* stay tuned!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### a trick to handle > 1-D \n",
    "* create one dimensional arrays of coordinate values\n",
    "* pass these to the .sel_points method\n",
    "* this is slow, but it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "lonVec = subset.coords['longitude'].where(subset.mask == 2).values\n",
    "lonVec = lonVec[np.isfinite(lonVec)]\n",
    "latVec = subset.coords['latitude'].where(subset.mask == 2).values\n",
    "latVec = latVec[np.isfinite(latVec)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "subset.isel(time=0).sel_points(longitude=lonVec, latitude=latVec, dim='points').t2m.mean(['points']).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### more examples:\n",
    "* an example combining multiple parameters within the same dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "(subset.t2m + subset.u10 / 2.3 - subset.v10 * 1.2).groupby('time.month').mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds.isel(time=0).plot()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
